{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARED TO V3\n",
    "\n",
    "# Started incorporating more raw datas and thinking about doing the calculation simultaneously for multiple RDs\n",
    "\n",
    "# jUST finished looping to get the p2p share"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb87f2c1",
   "metadata": {},
   "source": [
    "## Setting up the Lending Club time comparisons\n",
    "\n",
    "First: share living paycheck to paycheck by time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cbff71",
   "metadata": {},
   "source": [
    "**Importing libraries, loading csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cbc769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56eb4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'C:/Users/marco/Dropbox (MPD)/Analytics Argentina/Billable products/Surveys/Lending Club/All RDs'\n",
    "\n",
    "# Change the working directory to the specified path\n",
    "os.chdir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f005f44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List all files in the current working directory\n",
    "file_list = os.listdir(dir_path)\n",
    "\n",
    "# Print the file names\n",
    "for file_name in file_list:\n",
    "    print(file_name)\n",
    "    \n",
    "current_RD_name=\"LC19.csv\" # Hard coded reference\n",
    "RD_list=[\"LC17.csv\",\"LC18.csv\",\"LC19.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d35255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs to be updated periodically\n",
    "\n",
    "current_month = \"May 2023\"\n",
    "current_order = ['November 2021','December 2021','January 2022','February 2022', 'March 2022','April 2022',\n",
    "                 'May 2022', \"June 2022\", \"July 2022\", \"August 2022\", \"September 2022\", \"October 2022\",\n",
    "                 \"November 2022\", \"December 2022\", \"January 2023\",'February 2023',\"March 2023\",\"April 2023\",\"May 2023\"]\n",
    "\n",
    "study_months = {'LC01':'November 2021',\n",
    "                'LC02':'December 2021',\n",
    "                'LC03':'January 2022',\n",
    "                'LC04':'February 2022',\n",
    "                'LC05':'March 2022',\n",
    "                'LC06':'April 2022',\n",
    "                'LC07':'May 2022', \n",
    "                'LC08':\"June 2022\",\n",
    "                'LC09':\"July 2022\",\n",
    "                'LC10':\"August 2022\",\n",
    "                'LC11':\"September 2022\",\n",
    "                'LC12':\"October 2022\",\n",
    "                'LC13':\"November 2022\",\n",
    "                'LC14':\"December 2022\",\n",
    "                'LC15':\"January 2023\",\n",
    "                'LC16':'February 2023',\n",
    "                'LC17':\"March 2023\",\n",
    "                'LC18':\"April 2023\",\n",
    "                'LC19':\"May 2023\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062f9019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all raw datas into the environment as a dictionary\n",
    "# doing the same for a dictionary that has all the code equivalences per survey\n",
    "\n",
    "All_RDs = {}\n",
    "All_codebooks={}\n",
    "\n",
    "for file_name in RD_list:\n",
    "    # Remove the \".csv\" extension from the file name\n",
    "    dataframe_name = file_name.replace(\".csv\", \"\")\n",
    "    df = pd.read_csv(file_name, low_memory=False)\n",
    "    df=df.drop(0)\n",
    "    #turn all columns to lowercase\n",
    "    df.columns = df.columns.str.lower()\n",
    "    #removing whitenoise as all startdates must have data\n",
    "    df=df[df[\"startdate\"].notnull()]\n",
    "    print(dataframe_name)\n",
    "    print(f\"Load successful. {df.shape[0]} rows and {df.shape[1]} columns loaded into dataframe\")\n",
    "    All_RDs[dataframe_name] = df\n",
    "    \n",
    "    #loading dictionary with codes and questions\n",
    "    codebook=pd.read_csv(file_name, low_memory=False)\n",
    "    codebook=codebook.loc[0].to_dict()\n",
    "    All_codebooks[dataframe_name] = codebook\n",
    "\n",
    "print(\"*\"*20)\n",
    "# Access the DataFrames by their names\n",
    "print(\"Current Raw Datas in Environment: \")\n",
    "for name, dataframe in All_RDs.items():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b516a9",
   "metadata": {},
   "source": [
    "### Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cea9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to format dates because they got imported as numbers\n",
    "\n",
    "date_columns=['startdate','enddate']\n",
    "\n",
    "for name, df in All_RDs.items():\n",
    "    for col in date_columns:\n",
    "        df[col] = df[col].astype(float)\n",
    "        df[col] = df[col].astype(int)\n",
    "        df[col]= df[col]+ 693594 # Offset for converting to a valid date in the Gregorian calendar\n",
    "        df[col] = df[col].apply(lambda x: datetime.fromordinal(x))\n",
    "        df[col] = df[col].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    print(name)\n",
    "    print(np.sort(df.enddate.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to format weight as a float\n",
    "\n",
    "print(\"Weight sum should be 260M or similar\")\n",
    "for name, df in All_RDs.items():\n",
    "    df.weight=df.weight.astype(float)\n",
    "    print(name,\":\")\n",
    "    print(df.weight.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9cccde",
   "metadata": {},
   "source": [
    "### Share of consumers living paycheck to paycheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d705da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function that helps me find codes for questions\n",
    "#searching the codebook, as raw data has been stripped of the description\n",
    "\n",
    "def q_finder(word_to_find,edition):\n",
    "    for key, value in All_codebooks[edition].items():\n",
    "        try:\n",
    "            if word_to_find in value.lower():\n",
    "                print(f\"Word '{word_to_find}' found in key: {key} in {edition} codebook\")\n",
    "        except AttributeError:\n",
    "            print(\"one or more AttributeErrors in the process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a09b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in All_RDs.items():\n",
    "    q_finder(\"financial lifestyle\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f77e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_ls_codes={\"LC17\": \"D15\",\n",
    "             \"LC18\": \"D15\",\n",
    "             \"LC19\": \"D15\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f599e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full description is too long\n",
    "#Three mappings: Changing from first person to neutral wording, another for shorthand acess and a two group-only version\n",
    "#im appling the first directly into D15; this is means overwrite the raw data but i really see no use in the original wording\n",
    "\n",
    "p2p_cleaner = {'I live paycheck to paycheck and have issues paying my bills each month.': 'Paycheck to paycheck and struggling',\n",
    "           'I live paycheck to paycheck but am comfortably paying my bills each month.': 'Paycheck to paycheck but not struggling',\n",
    "           'I do not live paycheck to paycheck and have more than enough earnings to cover my bills each month.': 'Not paycheck to paycheck'}\n",
    "\n",
    "#\n",
    "\n",
    "p2p_short = {'Paycheck to paycheck and struggling':'Struggle',\n",
    "           'Paycheck to paycheck but not struggling': 'P2P',\n",
    "           'Not paycheck to paycheck':'NotP2P'}\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "p2p_TwoGroups = {'Paycheck to paycheck and struggling':'P2P',\n",
    "           'Paycheck to paycheck but not struggling': 'P2P',\n",
    "           'Not paycheck to paycheck':'NotP2P'}\n",
    "\n",
    "\n",
    "for name, df in All_RDs.items():\n",
    "    df.d15=df.d15.map(p2p_cleaner)\n",
    "    df['d15_short']=df.d15.map(p2p_short)\n",
    "    df['d15_TwoGroups']=df.d15.map(p2p_TwoGroups)\n",
    "\n",
    "# establishing the predifined order for later on:\n",
    "p2p_order = ['Paycheck to paycheck and struggling','Paycheck to paycheck but not struggling','Not paycheck to paycheck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c780215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking\n",
    "\n",
    "for name, df in All_RDs.items():\n",
    "    print(name,\"*\"*10)\n",
    "    print(df.d15.unique())\n",
    "    print(\"*\"*10)\n",
    "    print(df.d15_short.unique())\n",
    "    print(\"*\"*10)\n",
    "    print(df.d15_TwoGroups.unique()) # it's central to the analysis that there are no values outside the three expected values\n",
    "    print(\"*\"*10)\n",
    "    print(f'{df.d15.isnull().sum()} null values in target column')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e30bd73",
   "metadata": {},
   "source": [
    "### Share of consumers living paycheck to paycheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305dcad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the process is simple. you define a group (First it will be the whole sample) and split by financial lifestyle\n",
    "# add up all the weights in the p2p subgroup then divide by the summed weights in the whole set\n",
    "# then storing results in dataframe, this will simplify compilying over time and demo afterwards\n",
    "\n",
    "wSample={}\n",
    "ppwSample={}\n",
    "sample_share={}\n",
    "sample_shares_df=pd.DataFrame()\n",
    "\n",
    "for name, df in All_RDs.items():\n",
    "    wSample[name]=df.weight.sum()\n",
    "    ppwSample[name]=df[df['d15_TwoGroups']=='P2P']['weight'].sum()\n",
    "    sample_share[name]=ppwSample[name]/wSample[name]\n",
    "    \n",
    "    # this might look weird at this point, but i already know the shape of the dataframe i'll want down the road so im doing some\n",
    "    # tweaks to the dataframe: adding another column that specifies among what consumers im calculating (in this case sample)\n",
    "    # also renaming the axes to \"Group\", given that i may have the same calculation for different groups in a same table\n",
    "\n",
    "    if name=='LC17': # HARD CODED!!!\n",
    "        sample_shares_df=pd.DataFrame(sample_share[name], index=['Sample'], columns=[study_months[name]])\n",
    "        sample_shares_df=sample_shares_df.rename_axis('Group')\n",
    "        sample_shares_df.insert(0,\"Two-level\",'Sample') #hard coded\n",
    "    else:\n",
    "        sample_shares_df[study_months[name]]=sample_share[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51556f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_shares_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d1b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE  # HERE # HERE # HERE # HERE # HERE # HERE # HERE # HERE # HERE # HERE # HERE # HERE # HERE # HERE # HERE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc897abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the shares for each group instead of one metric is (slightly) different\n",
    "# using groupby to sum weights per group, then again divide by the total weight\n",
    "\n",
    "# Splitting sample by p2p status + summing weights\n",
    "p2p_groups=df.groupby('D15') #hard coded\n",
    "p2p_weight_subtotals = p2p_groups['weight'].sum()\n",
    "\n",
    "#total weights (denominator)\n",
    "total_weight = p2p_weight_subtotals.sum()\n",
    "weight_shares = p2p_weight_subtotals / total_weight\n",
    "\n",
    "sample_p2p_shares = pd.DataFrame({current_month: weight_shares}) #Date is hard coded\n",
    "\n",
    "# same edits to the dataframe\n",
    "\n",
    "sample_p2p_shares=sample_p2p_shares.reindex(p2p_order)\n",
    "sample_p2p_shares=sample_p2p_shares.rename_axis('Group')\n",
    "sample_p2p_shares.insert(0,\"Two-level\",'Sample')\n",
    "sample_p2p_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40770ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_p2p_shares['April 2023'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e871ab",
   "metadata": {},
   "source": [
    "#### Share of consumers living paycheck to paycheck: Demo comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1366b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process is the same, only difference is that i need to get all the denominators first which is the population of each demo group\n",
    "# defining my target demographic subsets and the respective populations by split\n",
    "# Age, income (3 and 5 splits), and gender. P2P not included because its the baseline split\n",
    "\n",
    "wP2P = df.groupby('D15')['weight'].sum()\n",
    "wP2P_TwoGroups = df.groupby('D15_TwoGroups')['weight'].sum()\n",
    "wGens = df.groupby('Generation')['weight'].sum()\n",
    "wIncome5 = df.groupby('Q_income_RB')['weight'].sum()\n",
    "wIncome3 = df.groupby('income_3G')['weight'].sum()\n",
    "wGender = df.groupby('L_gender')['weight'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a0b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two silly checks  \n",
    "print(\"Number of consumers by generation (should add up to 260 or similar):\")\n",
    "print(wGens/1000000)\n",
    "print(\"*\"*10)\n",
    "print(\"Share of consumers by income:\")\n",
    "print(wIncome5/260000000) #go back and ensure these shares match the current lending analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54f767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paycheck to paycheck populations withing each subgroup of each split\n",
    "\n",
    "ppwGens=df[df['D15_TwoGroups']=='P2P'].groupby('Generation')['weight'].sum()\n",
    "ppwInc5=df[df['D15_TwoGroups']=='P2P'].groupby('Q_income_RB')['weight'].sum()\n",
    "ppwInc3=df[df['D15_TwoGroups']=='P2P'].groupby('income_3G')['weight'].sum()\n",
    "ppwGender=df[df['D15_TwoGroups']=='P2P'].groupby('L_gender')['weight'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8039b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eyeball shares of p2p by generation, make sense?\n",
    "ppwGens/wGens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acbcf8d",
   "metadata": {},
   "source": [
    "#### Consolidating a demo p2p time comparison single table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84579716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generations\n",
    "gen_shares=ppwGens/wGens\n",
    "gen_shares=pd.DataFrame(index=gen_shares.index, data=gen_shares.values, columns=['April 2023'])\n",
    "gen_order = ['Generation Z', 'Millennials', 'Generation X','Baby boomers and seniors']\n",
    "gen_shares=gen_shares.reindex(gen_order)\n",
    "gen_shares=gen_shares.rename_axis('Group')\n",
    "gen_shares.insert(0,\"Two-level\",'Generation') #hard coded\n",
    "gen_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4067e439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#B) Income: 5 groups\n",
    "\n",
    "income5_shares=ppwInc5/wIncome5\n",
    "income5_shares=pd.DataFrame(index=income5_shares.index, data=income5_shares.values, columns=['April 2023'])\n",
    "inc5_order = ['Under $50K', '$50K-$100K', '$100K-$150K','$150K-$200K','$200K-$250K','$250K+']\n",
    "income5_shares=income5_shares.reindex(inc5_order)\n",
    "income5_shares=income5_shares.rename_axis('Group')\n",
    "income5_shares.insert(0,\"Two-level\",'Income 5') #hard coded\n",
    "income5_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5606a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C) Income: 3 groups\n",
    "\n",
    "income3_shares=ppwInc3/wIncome3\n",
    "income3_shares=pd.DataFrame(index=income3_shares.index, data=income3_shares.values, columns=['April 2023'])\n",
    "inc3_order = ['Under $50K', '$50K-$100K', '$100K+']\n",
    "income3_shares=income3_shares.reindex(inc3_order)\n",
    "income3_shares=income3_shares.rename_axis('Group')\n",
    "income3_shares.insert(0,\"Two-level\",'Income 3') #hard coded\n",
    "income3_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0934a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender\n",
    "\n",
    "gender_shares=ppwGender/wGender\n",
    "gender_shares=pd.DataFrame(index=gender_shares.index, data=gender_shares.values, columns=['April 2023'])\n",
    "gender_order = ['Female', 'Male']\n",
    "gender_shares=gender_shares.reindex(gender_order)\n",
    "gender_shares=gender_shares.rename_axis('Group')\n",
    "gender_shares.insert(0,\"Two-level\",'Gender') #hard coded\n",
    "gender_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98524eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Putting it all toghether\n",
    "p2p_all_demos=pd.concat([sample_share,gen_shares,income3_shares,income5_shares,gender_shares],axis=0)\n",
    "p2p_all_demos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884a6e92",
   "metadata": {},
   "source": [
    "### Share of consumers struggling to pay bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4f3e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# financially struggling populations withing each subgroup of each split\n",
    "\n",
    "ppswSample=df[df['D15']=='Paycheck to paycheck and struggling']['weight'].sum()\n",
    "ppswGens=df[df['D15']=='Paycheck to paycheck and struggling'].groupby('Generation')['weight'].sum() \n",
    "ppswInc5=df[df['D15']=='Paycheck to paycheck and struggling'].groupby('Q_income_RB')['weight'].sum()\n",
    "ppswInc3=df[df['D15']=='Paycheck to paycheck and struggling'].groupby('income_3G')['weight'].sum()\n",
    "ppswGender=df[df['D15']=='Paycheck to paycheck and struggling'].groupby('L_gender')['weight'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8e5aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eyeballing one example - income 3g\n",
    "ppswInc3/wIncome3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55bffe8",
   "metadata": {},
   "source": [
    "#### Consolidating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b82260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample\n",
    "\n",
    "struggling_share=ppswSample/wSample\n",
    "\n",
    "struggling_share=pd.DataFrame(struggling_share, index=['Sample'], columns=[current_month])\n",
    "struggling_share=struggling_share.rename_axis('Group')\n",
    "struggling_share.insert(0,\"Two-level\",'Sample') #hard coded\n",
    "struggling_share\n",
    "\n",
    "#A) Generations\n",
    "gen_shares_struggling=ppswGens/wGens\n",
    "gen_shares_struggling=pd.DataFrame(index=gen_shares_struggling.index, data=gen_shares_struggling.values, columns=['April 2023'])\n",
    "gen_shares_struggling=gen_shares_struggling.reindex(gen_order) #order was already defined in p2p section\n",
    "gen_shares_struggling=gen_shares_struggling.rename_axis('Group')\n",
    "gen_shares_struggling.insert(0,\"Two-level\",'Generation') #hard coded\n",
    "\n",
    "#B) Income: 5 groups\n",
    "\n",
    "income5_shares_struggling=ppswInc5/wIncome5\n",
    "income5_shares_struggling=pd.DataFrame(\n",
    "    index=income5_shares_struggling.index, data=income5_shares_struggling.values, columns=['April 2023'])\n",
    "income5_shares_struggling=income5_shares_struggling.reindex(inc5_order)\n",
    "income5_shares_struggling=income5_shares_struggling.rename_axis('Group')\n",
    "income5_shares_struggling.insert(0,\"Two-level\",'Income 5') #hard coded\n",
    "\n",
    "#C) Income: 3 groups\n",
    "\n",
    "income3_shares_struggling=ppswInc3/wIncome3\n",
    "income3_shares_struggling=pd.DataFrame(\n",
    "    index=income3_shares_struggling.index, data=income3_shares_struggling.values, columns=['April 2023'])\n",
    "income3_shares=income3_shares_struggling.reindex(inc3_order)\n",
    "income3_shares=income3_shares_struggling.rename_axis('Group')\n",
    "income3_shares_struggling.insert(0,\"Two-level\",'Income 3') #hard coded\n",
    "\n",
    "\n",
    "#D) Gender\n",
    "\n",
    "gender_shares_struggling=ppswGender/wGender\n",
    "gender_shares_struggling=pd.DataFrame(\n",
    "    index=gender_shares_struggling.index, data=gender_shares_struggling.values, columns=['April 2023'])\n",
    "gender_shares_struggling=gender_shares_struggling.reindex(gender_order)\n",
    "gender_shares_struggling=gender_shares_struggling.rename_axis('Group')\n",
    "gender_shares_struggling.insert(0,\"Two-level\",'Gender') #hard coded\n",
    "\n",
    "## Putting it all toghether\n",
    "p2p_struggling_all_demos=pd.concat(\n",
    "    [struggling_share,gen_shares_struggling,income3_shares_struggling,income5_shares_struggling,gender_shares_struggling],axis=0)\n",
    "p2p_struggling_all_demos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4820c33",
   "metadata": {},
   "source": [
    "### Sumproduct template: average savings, average credit score\n",
    "\n",
    "#### Average savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9401b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to shorten typing in the future when averaging numerical values using the weights\n",
    "\n",
    "# this one only works in the full sample\n",
    "def weighted_average(values):\n",
    "    if len(values) != len(df.weight):\n",
    "        raise ValueError(\"Number of values and weights must be the same.\")\n",
    "    \n",
    "    total_weight = sum(df.weight)\n",
    "    weighted_sum = sum(value * weight for value, weight in zip(values, df.weight))\n",
    "    \n",
    "    return weighted_sum / total_weight\n",
    "\n",
    "def weighted_average_group(values, weights):\n",
    "    if len(values) != len(weights):\n",
    "        raise ValueError(\"Number of values and weights must be the same.\")\n",
    "    \n",
    "    total_weight = sum(weights)\n",
    "    weighted_sum = sum(value * weight for value, weight in zip(values, weights))\n",
    "    \n",
    "    return weighted_sum / total_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b8f3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_finder(\"savings\") # its D16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ef3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.D16.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379911bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['D16'].value_counts(normalize=True).sort_index().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7ae20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "savings_to_numerical={\n",
    "    'I have no savings.':0,\n",
    "    'Less than $500':250,\n",
    "    'Between $500 and $1,000':750,\n",
    "    'Between $1,001 and $2,500':1750,\n",
    "    'Between $2,501 and $5,000':3750, \n",
    "    'Between $5,001 and $10,000':7500,\n",
    "    'Between $10,001 and $15,000':12500,\n",
    "    'Between $15,001 and $25,000':20000,\n",
    "    'More than $25,000':32500    \n",
    "}\n",
    "\n",
    "df['D16_numerical']=df.D16.map(savings_to_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea9ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['D16_numerical'].value_counts(normalize=True).sort_index().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb57151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "savings={current_month:weighted_average(df['D16_numerical'])}\n",
    "\n",
    "sample_savings = pd.DataFrame(\n",
    "    data=savings.values(),\n",
    "    index= [\"Sample\"],\n",
    "    columns= savings.keys(),\n",
    ")\n",
    "sample_savings.index.name = 'Group'\n",
    "sample_savings.insert(0,\"Two-level\",'Sample') #hard coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6b586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bb80fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by financial lifestyle\n",
    "p2p_savings=df.groupby('D15').apply(lambda x: weighted_average_group(x['D16_numerical'], x['weight']))\n",
    "p2p_savings=pd.DataFrame(index=p2p_savings.index, data=p2p_savings.values, columns=[current_month])\n",
    "p2p_savings=p2p_savings.reindex(p2p_order) #order was already defined in p2p section\n",
    "p2p_savings=p2p_savings.rename_axis('Group')\n",
    "p2p_savings.insert(0,\"Two-level\",'Financial lifestyle') #hard coded\n",
    "\n",
    "#generation\n",
    "gen_savings=df.groupby('Generation').apply(lambda x: weighted_average_group(x['D16_numerical'], x['weight']))\n",
    "gen_savings=pd.DataFrame(index=gen_savings.index, data=gen_savings.values, columns=[current_month])\n",
    "gen_savings=gen_savings.reindex(gen_order) #order was already defined in p2p section\n",
    "gen_savings=gen_savings.rename_axis('Group')\n",
    "gen_savings.insert(0,\"Two-level\",'Generation') #hard coded\n",
    "\n",
    "#Income: 3 groups\n",
    "\n",
    "inc3_savings=df.groupby('income_3G').apply(lambda x: weighted_average_group(x['D16_numerical'], x['weight']))\n",
    "inc3_savings=pd.DataFrame(index=inc3_savings.index, data=inc3_savings.values, columns=[current_month])\n",
    "inc3_savings=inc3_savings.reindex(inc3_order) #order was already defined in p2p section\n",
    "inc3_savings=inc3_savings.rename_axis('Group')\n",
    "inc3_savings.insert(0,\"Two-level\",'Income 3') #hard coded\n",
    "\n",
    "#Income: 5 groups\n",
    "\n",
    "inc5_savings=df.groupby('Q_income_RB').apply(lambda x: weighted_average_group(x['D16_numerical'], x['weight']))\n",
    "inc5_savings=pd.DataFrame(index=inc5_savings.index, data=inc5_savings.values, columns=[current_month])\n",
    "inc5_savings=inc5_savings.reindex(inc5_order) #order was already defined in p2p section\n",
    "inc5_savings=inc5_savings.rename_axis('Group')\n",
    "inc5_savings.insert(0,\"Two-level\",'Income 5') #hard coded\n",
    "\n",
    "#Gender\n",
    "\n",
    "gender_savings=df.groupby('L_gender').apply(lambda x: weighted_average_group(x['D16_numerical'], x['weight']))\n",
    "gender_savings=pd.DataFrame(index=gender_savings.index, data=gender_savings.values, columns=[current_month])\n",
    "gender_savings=gender_savings.reindex(gender_order) #order was already defined in p2p section\n",
    "gender_savings=gender_savings.rename_axis('Group')\n",
    "gender_savings.insert(0,\"Two-level\",'Gender') #hard coded\n",
    "\n",
    "## Putting it all toghether\n",
    "savings_tc=pd.concat(\n",
    "    [sample_savings,p2p_savings,gen_savings,inc3_savings,inc5_savings,gender_savings],axis=0)\n",
    "\n",
    "savings_tc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42051531",
   "metadata": {},
   "source": [
    "#### Average credit score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbe3560",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_finder(\"credit score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af42c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will need to drop nulls for the average so cant work with original dataframe\n",
    "\n",
    "df_cscores=df.copy()\n",
    "df_cscores=df_cscores[['D28','D15','D15_TwoGroups','Generation','Q_income_RB','income_3G','L_gender','weight']]\n",
    "df_cscores=df_cscores[df_cscores.D28 != \"I don't know / I am not sure\"]\n",
    "df_cscores=df_cscores[df_cscores.D28 != \"I don't have a credit score\"]\n",
    "df_cscores.D28.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec5568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_to_numerical={\n",
    "    \"300 to 400\":350,\n",
    "    \"401 to 500\":450,\n",
    "    \"501 to 600\":550,\n",
    "    \"601 to 650\":625,\n",
    "    \"651 to 700\":675,\n",
    "    \"701 to 750\":725,\n",
    "    \"751 to 800\":775.5,\n",
    "    \"801 to 850\":825,  \n",
    "}\n",
    "\n",
    "df_cscores['D28_numerical']=df_cscores.D28.map(scores_to_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc08b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cscores.D28_numerical.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22842a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_scores=df_cscores.D28_numerical*df_cscores.weight\n",
    "average_credit_score=weighted_scores.sum()/df_cscores.weight.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a0d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_cscores = pd.DataFrame(\n",
    "    data=average_credit_score,\n",
    "    index= [\"Sample\"],\n",
    "    columns= [current_month],\n",
    ")\n",
    "sample_cscores.index.name = 'Group'\n",
    "sample_cscores.insert(0,\"Two-level\",'Sample') #hard coded\n",
    "sample_cscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335bd50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by financial lifestyle\n",
    "p2p_cscores=df_cscores.groupby('D15').apply(lambda x: weighted_average_group(x['D28_numerical'], x['weight']))\n",
    "p2p_cscores=pd.DataFrame(index=p2p_cscores.index, data=p2p_cscores.values, columns=[current_month])\n",
    "p2p_cscores=p2p_cscores.reindex(p2p_order) #order was already defined in p2p section\n",
    "p2p_cscores=p2p_cscores.rename_axis('Group')\n",
    "p2p_cscores.insert(0,\"Two-level\",'Financial lifestyle') #hard coded\n",
    "\n",
    "#generation\n",
    "gen_cscores=df_cscores.groupby('Generation').apply(lambda x: weighted_average_group(x['D28_numerical'], x['weight']))\n",
    "gen_cscores=pd.DataFrame(index=gen_cscores.index, data=gen_cscores.values, columns=[current_month])\n",
    "gen_cscores=gen_cscores.reindex(gen_order) #order was already defined in p2p section\n",
    "gen_cscores=gen_cscores.rename_axis('Group')\n",
    "gen_cscores.insert(0,\"Two-level\",'Generation') #hard coded\n",
    "\n",
    "#Income: 3 groups\n",
    "\n",
    "inc3_cscores=df_cscores.groupby('income_3G').apply(lambda x: weighted_average_group(x['D28_numerical'], x['weight']))\n",
    "inc3_cscores=pd.DataFrame(index=inc3_cscores.index, data=inc3_cscores.values, columns=[current_month])\n",
    "inc3_cscores=inc3_cscores.reindex(inc3_order) #order was already defined in p2p section\n",
    "inc3_cscores=inc3_cscores.rename_axis('Group')\n",
    "inc3_cscores.insert(0,\"Two-level\",'Income 3') #hard coded\n",
    "\n",
    "#Income: 5 groups\n",
    "\n",
    "inc5_cscores=df_cscores.groupby('Q_income_RB').apply(lambda x: weighted_average_group(x['D28_numerical'], x['weight']))\n",
    "inc5_cscores=pd.DataFrame(index=inc5_cscores.index, data=inc5_cscores.values, columns=[current_month])\n",
    "inc5_cscores=inc5_cscores.reindex(inc5_order) #order was already defined in p2p section\n",
    "inc5_cscores=inc5_cscores.rename_axis('Group')\n",
    "inc5_cscores.insert(0,\"Two-level\",'Income 5') #hard coded\n",
    "\n",
    "#Gender\n",
    "\n",
    "gender_cscores=df_cscores.groupby('L_gender').apply(lambda x: weighted_average_group(x['D28_numerical'], x['weight']))\n",
    "gender_cscores=pd.DataFrame(index=gender_cscores.index, data=gender_cscores.values, columns=[current_month])\n",
    "gender_cscores=gender_cscores.reindex(gender_order) #order was already defined in p2p section\n",
    "gender_cscores=gender_cscores.rename_axis('Group')\n",
    "gender_cscores.insert(0,\"Two-level\",'Gender') #hard coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea8ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Putting it all toghether\n",
    "cscores_tc=pd.concat(\n",
    "    [sample_cscores,p2p_cscores,gen_cscores,inc3_cscores,inc5_cscores,gender_cscores],axis=0)\n",
    "\n",
    "cscores_tc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ca6536",
   "metadata": {},
   "source": [
    "### Share making payments related to credit products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fc2014",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_finder(\"credit product\") # its D16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e55160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a bit tricky because data is scattered in multiple columns\n",
    "# i start off by fetching all unique values other than 0 in each column\n",
    "# then its just about looping throughout and summing the weights of the rows when code=value\n",
    "\n",
    "cproduct_cols=[]\n",
    "\n",
    "for key in codebook:\n",
    "    if 'D26' in key:\n",
    "        cproduct_cols.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb375c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cproduct_cols #some non raw data columns here, dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d039f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cproduct_cols.remove('D26.v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6003fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list with all credit products listed in each column (one each, excluding zeros which mean don't have)\n",
    "cproducts=[]\n",
    "\n",
    "for col in cproduct_cols:\n",
    "    cproducts.extend(df[col].unique()[df[col].unique()!='0'].tolist())\n",
    "\n",
    "cproducts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e79929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now looping through and summing the weights for all affirmative responses per product\n",
    "\n",
    "\n",
    "cproduct_shares={}\n",
    "for col, product in zip(cproduct_cols,cproducts):\n",
    "    share_using_cp=df[df[col]==product].weight.sum()/wSample\n",
    "    cproduct_shares[product]=share_using_cp\n",
    "    \n",
    "cproduct_shares=pd.DataFrame(data=cproduct_shares.values(), index=cproduct_shares.keys(), columns=[current_month])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39b7180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Im going to use the current ranking to create the pre-established order\n",
    "# i cannot let this float because i run a risk of appending stuff in mixed places if the order changes\n",
    "# cproduct_shares.sort_values(by=current_month,ascending=False).index.tolist()\n",
    "\n",
    "# 'None' goes last\n",
    "\n",
    "cproduct_order=['Credit card',\n",
    " 'Auto loan',\n",
    " 'Mortgage loan, refinancing',\n",
    " 'Personal loan',\n",
    " 'Buy Now, Pay Later (installment credit)',\n",
    " 'Mortgage loan, first-time buying',\n",
    " 'Student loan',\n",
    " 'Home equity loan',\n",
    " 'Debt consolidation loan',\n",
    " 'Business lines of credit',\n",
    " 'Second mortgage',\n",
    "  'None of these']\n",
    "\n",
    "cproduct_shares.reindex(cproduct_order)\n",
    "cproduct_shares=cproduct_shares.rename_axis('Group')\n",
    "cproduct_shares.insert(0,\"Two-level\",'Sample') #hard coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce624cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cproduct_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b485d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cproducts_tc = pd.DataFrame(columns=['Two-level','Product',current_month])\n",
    "\n",
    "# by financial lifestyle\n",
    "\n",
    "for col, product in zip(cproduct_cols,cproducts):\n",
    "    cpw_p2p=df[df[col]==product].groupby('D15')['weight'].sum()\n",
    "    product_table=pd.DataFrame(data=cpw_p2p/wP2P) \n",
    "    product_table=product_table.reindex(p2p_order)\n",
    "    product_table = product_table.rename(columns={'weight': current_month})\n",
    "    product_table.insert(0,\"Two-level\",'Financial lifestyle') #hard coded\n",
    "    product_table.insert(1,\"Product\",product) #hard coded\n",
    "    cproducts_tc= pd.concat([cproducts_tc, product_table])\n",
    "    cproducts_tc= cproducts_tc.rename_axis('Group')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
